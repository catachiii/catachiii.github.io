<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="UdWl-KSPOvnujiViTuJObDjoybkQn0GxRLSJVzePntc"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Jin Cheng </title> <meta name="author" content="Jin Cheng"> <meta name="description" content="Personal website of Jin Cheng, a doctoral researcher in robotics at ETH Zürich. "> <meta property="og:site_name" content="Jin Cheng"> <meta property="og:type" content="website"> <meta property="og:title" content="Jin Cheng | about"> <meta property="og:url" content="https://jin-cheng.me/"> <meta property="og:description" content="Personal website of Jin Cheng, a doctoral researcher in robotics at ETH Zürich. "> <meta property="og:image" content="/assets/img/jincheng.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="about"> <meta name="twitter:description" content="Personal website of Jin Cheng, a doctoral researcher in robotics at ETH Zürich. "> <meta name="twitter:image" content="/assets/img/jincheng.jpg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Jin Cheng"
        },
        "url": "https://jin-cheng.me/",
        "@type": "WebSite",
        "description": "Personal website of Jin Cheng, a doctoral researcher in robotics at ETH Zürich.
",
        "headline": "about",
        
        "name": "Jin Cheng",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?489d685e9c159d42aa959bcf422eccae"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jin-cheng.me/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">gallery </a> </li> <li class="nav-item "> <a class="nav-link" href="/reading/">reading </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Jin Cheng </h1> <p class="desc"><img src="../assets/img/chinese_name.png" alt="jin_cheng" width="80"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/jincheng-480.webp 480w,/assets/img/jincheng-800.webp 800w,/assets/img/jincheng-1400.webp 1400w," type="image/webp" sizes="(min-width: 1000px) 291.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/jincheng.jpg?34de172b4503b9e6c35cfffd98baaa20" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="jincheng.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Hello there!</p> <p>I’m a doctoral student in Computer Science at <img src="../assets/img/eth_short.png" alt="eth" height="20"> <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zürich</a>, Switzerland 🇨🇭, affiliated with <a href="http://crl.ethz.ch/" rel="external nofollow noopener" target="_blank">Computational Robotics Lab</a>, advised by <img src="../assets/img/eth_short.png" alt="eth" height="20"> <a href="http://crl.ethz.ch/people/coros/index.html" rel="external nofollow noopener" target="_blank">Prof. Stelian Coros</a> and <img src="../assets/img/cmu-lettermark-r.png" alt="cmu" height="10"> <a href="https://www.gshi.me/" rel="external nofollow noopener" target="_blank">Prof. Guanya Shi</a>.</p> <p>Prior to this, I received my master’s degree in mechanical engineering at <img src="../assets/img/eth_short.png" alt="eth" height="20"> <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zürich</a> and my bachelor’s degree in vehicle engineering at <img src="../assets/img/thu_short.png" alt="eth" height="15"> <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>.</p> <h4 id="--research">- research</h4> <p>My research interest lies in empowering mobile robots with the ability of locomotion and manipulation through reinforcement learning. I mainly focus on legged systems such as quadrupeds 🐕🐈, humanoids 🏃🏻💃🏻.</p> <h4 id="--misc">- misc.</h4> <p>Other than professional bios, I am from <a href="https://goo.gl/maps/dJPha9VP7CFDoNqg7" rel="external nofollow noopener" target="_blank">Chongqing</a>, southwest of China. I am extremely fond of <a href="https://en.wikipedia.org/wiki/Chongqing_hot_pot" rel="external nofollow noopener" target="_blank">Chongqing hot pot</a>.</p> <p>Besides, I love to read and spend a lot of time with books, especially in modern and contemporary literature. My favorite authors are <a href="https://en.wikipedia.org/wiki/Haruki_Murakami" rel="external nofollow noopener" target="_blank">Haruki Murakami</a>, <a href="https://en.wikipedia.org/wiki/Natsume_S%C5%8Dseki" rel="external nofollow noopener" target="_blank">Natsume Soseki</a>, <a href="https://en.wikipedia.org/wiki/Albert_Camus" rel="external nofollow noopener" target="_blank">Albert Camus</a> and <a href="https://en.wikipedia.org/wiki/Gabriel_Garc%C3%ADa_M%C3%A1rquez" rel="external nofollow noopener" target="_blank">Gabriel García Márquez</a>.</p> <p>I also enjoy photography 📷, video games 🎮, and movies 🍿. In my free time, I like making latte arts ☕️, playing tennis 🎾, and snowboarding 🏂.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 20vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 11, 2025</th> <td> 📑 I am very delighted to share my collaboration work with <a href="https://sites.google.com/view/sungjoon-choi/home" rel="external nofollow noopener" target="_blank">Robot Intelligence Lab (RILAB)</a> at Korea University, <em>Spatio-Temporal Motion Retargeting for Quadruped Robots</em>, has been accepted for publication in IEEE Transactions on Robotics (T-RO). </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 11, 2025</th> <td> 📑 I am happy to share my collaboration work with <a href="https://www.marmotlab.org/" rel="external nofollow noopener" target="_blank">Multi-Agent Robotic Motion Laboratory</a> at National University of Singapore, <em>SATA: Safe and Adaptive Torque-Based Locomotion Policies Inspired by Animal Learning</em> has been accepted for publication in the Proceedings of Robotics: Science and Systems (RSS 2025). </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 28, 2025</th> <td> 📑 I am happy to share my collaboration work with <a href="https://www.marmotlab.org/" rel="external nofollow noopener" target="_blank">Multi-Agent Robotic Motion Laboratory</a> at National University of Singapore, <em>DARE: Diffusion Policy for Autonomous Robot Exploration</em> has been accepted for publication in the Proceedings of 2025 IEEE International Conference on Robotics and Automation (ICRA 2025). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 24, 2024</th> <td> 🇫🇷 I spent a wonderful week at the 2024 IEEE RAS 23rd International Conference on Humanoid Robots (<a href="https://2024.ieee-humanoids.org/" rel="external nofollow noopener" target="_blank">Humanoids</a>) in Nancy, France. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 11, 2024</th> <td> 🇩🇪 I spent a wonderful week at the 2024 Conference on Robot Learning (<a href="https://www.corl.org/" rel="external nofollow noopener" target="_blank">CoRL 2024</a>) in Munich, Germany. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 04, 2024</th> <td> 📑 I am happy to share our recent work from <a href="http://crl.ethz.ch/" rel="external nofollow noopener" target="_blank">Computational Robotics Lab</a>, <em>RobotKeyframing: Learning Locomotion with High-Level Objectives via Mixture of Dense and Sparse Rewards</em> has been accepted for publication on 2024 Conference on Robot Learning (<a href="https://www.corl.org/" rel="external nofollow noopener" target="_blank">CoRL 2024</a>). Please check our <a href="https://sites.google.com/view/robot-keyframing" rel="external nofollow noopener" target="_blank">website</a> for more details. </td> </tr> <tr> <th scope="row" style="width: 20%">May 17, 2024</th> <td> 🇯🇵 I spent a wonderful week at the 2024 International Conference on Robotics and Automation (<a href="https://2024.ieee-icra.org/" rel="external nofollow noopener" target="_blank">ICRA 2024</a>) in Yokohama, Japan. </td> </tr> <tr> <th scope="row" style="width: 20%">May 15, 2024</th> <td> 📑 I am happy to share our recent work <a href="https://sites.google.com/view/diversity-via-duality/" rel="external nofollow noopener" target="_blank"><em>Offline Diversity Maximization Under Imitation Constraints</em></a> from <a href="https://al.is.mpg.de/" rel="external nofollow noopener" target="_blank">Autonomous Learning group</a> at <a href="https://is.mpg.de/" rel="external nofollow noopener" target="_blank">Max Planck Institute for Intelligent Systems (MPI-IS)</a> has been accepted for publication on the first Reinforcement Learning Conference (<a href="https://rl-conference.cc/" rel="external nofollow noopener" target="_blank">RLC 2024</a>). Please check the <a href="https://tinyurl.com/diversity-via-duality" rel="external nofollow noopener" target="_blank">project website</a> for more details. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 29, 2024</th> <td> 📑 I am happy to share our recent work from <a href="https://al.is.mpg.de/" rel="external nofollow noopener" target="_blank">Autonomous Learning group</a> at <a href="https://is.mpg.de/" rel="external nofollow noopener" target="_blank">Max Planck Institute for Intelligent Systems (MPI-IS)</a>, <em>Learning Diverse Skills for Local Navigation under Multi-constraint Optimality</em> accepted for publication in the Proceedings of 2024 IEEE International Conference on Robotics and Automation (ICRA 2024). Please check the <a href="https://sites.google.com/view/icra2024-dominic" rel="external nofollow noopener" target="_blank">project website</a> for more details. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 10, 2023</th> <td> 🇺🇸 I spent a wonderful week at the 2023 Conference on Robot Learning (<a href="https://www.corl2023.org/" rel="external nofollow noopener" target="_blank">CoRL 2023</a>) in Atlanta, United States. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 01, 2023</th> <td> 🏫 I started my doctoral journey in Computer Science at <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zürich</a>, Switzerland. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 23, 2023</th> <td> 📑 I am happy to share our recent work from <a href="http://crl.ethz.ch/" rel="external nofollow noopener" target="_blank">Computational Robotics Lab</a>, <em>RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion</em> has been published to the IEEE Robotics and Automation Letters (RA-L) journal. Please check the <a href="https://donghok.me/rl-plus-model-based-control/" rel="external nofollow noopener" target="_blank">project website</a> for more details. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 31, 2023</th> <td> 🎓 I received my master degree in mechanical engineering from <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zürich</a>, Switzerland. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 03, 2023</th> <td> 🇬🇧 I spent a wonderful week at the 2023 International Conference on Robotics and Automation (<a href="https://www.icra2023.org/" rel="external nofollow noopener" target="_blank">ICRA 2023</a>) in London, United Kingdom. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 01, 2023</th> <td> 🇩🇪 I started to work as a research intern in <a href="https://al.is.mpg.de/" rel="external nofollow noopener" target="_blank">Autonomous Learning group</a> at <a href="https://is.mpg.de/" rel="external nofollow noopener" target="_blank">Max Planck Institute for Intelligent Systems (MPI-IS)</a>, Tübingen, Germany, under the supervision of <a href="https://al.is.mpg.de/person/gmartius" rel="external nofollow noopener" target="_blank">Prof. Dr. Georg Martius</a>. I will be working on reinforcement learning with unsupervised skill discovery for quadruped robots. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 05, 2022</th> <td> 🇨🇭 I started to work as a research assistant in <a href="http://crl.ethz.ch/" rel="external nofollow noopener" target="_blank">Computational Robotics Lab</a> at ETH Zürich under the supervision of <a href="http://crl.ethz.ch/people/coros/index.html" rel="external nofollow noopener" target="_blank">Prof. Dr. Stelian Coros</a>. I will be working on imitation learning for quadruped robots. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 29, 2022</th> <td> 🇯🇵 I spent a wonderful week at the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<a href="https://iros2022.org/" rel="external nofollow noopener" target="_blank">IROS 2022</a>) in Kyoto, Japan. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 03, 2022</th> <td> 📋 I successfully defended my master thesis in <a href="https://rsl.ethz.ch/" rel="external nofollow noopener" target="_blank">Robotic Systems Lab</a> under the supervision of Alexander Reske, Nikita Rudin, Fabian Jenelten, <a href="https://www.linkedin.com/in/farbod-farshidian-b8b39971/" rel="external nofollow noopener" target="_blank">Dr. Farbod Farshidian</a>, <a href="https://mavt.ethz.ch/people/person-detail.hutter.html" rel="external nofollow noopener" target="_blank">Prof. Dr. Marco Hutter</a>. I worked on imitating model predictive controller using reinforcement learning for perceptive locomotion for <a href="https://rsl.ethz.ch/robots-media/anymal.html" rel="external nofollow noopener" target="_blank">ANYmal</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 15, 2022</th> <td> 📝 I started to work as head teaching assistant for <a href="https://idsc.ethz.ch/education/lectures/optimal-control.html" rel="external nofollow noopener" target="_blank">Dynamic Programming and Optimal Control</a> in HS22 from <a href="https://raffaello.name/" rel="external nofollow noopener" target="_blank">Prof. Dr. Raffaello D’Andrea</a> at ETH Zürich. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 30, 2022</th> <td> 📑 I am happy to announce that our recent work from <a href="https://rsl.ethz.ch/" rel="external nofollow noopener" target="_blank">Robotic Systems Lab</a>, <em>Haptic Teleoperation of High-dimensional Robotic Systems Using a Feedback MPC Framework</em> has been accepted for publication in the Proceedings of the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<a href="https://iros2022.org/" rel="external nofollow noopener" target="_blank">IROS 2022</a>), which will be held on October 23-27, 2022, Kyoto, Japan. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 10, 2022</th> <td> 🎉 I was awarded Outstanding Teaching Assistant Award from Department of Mechanical and Process Engineering (D-MAVT), ETH Zürich, check <a href="https://mavt.ethz.ch/news-and-events/d-mavt-news/2022/03/ta-award-hs2021.html" rel="external nofollow noopener" target="_blank">website</a>, <a href="https://twitter.com/eth_dmavt/status/1503292267100004358?s=46" rel="external nofollow noopener" target="_blank">post</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 15, 2022</th> <td> 📝 I started to work as a student teaching assistant for <a href="https://idsc.ethz.ch/education/lectures/recursive-estimation.html" rel="external nofollow noopener" target="_blank">Recursive Estimation</a> in FS22 from <a href="https://raffaello.name/" rel="external nofollow noopener" target="_blank">Prof. Dr. Raffaello D’Andrea</a> at ETH Zürich. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 21, 2022</th> <td> 📋 I successfully finished my semester project in <a href="https://rsl.ethz.ch/" rel="external nofollow noopener" target="_blank">Robotic Systems Lab</a> under the supervision of Dr. Firas Abi-Farraj, <a href="https://www.linkedin.com/in/farbod-farshidian-b8b39971/" rel="external nofollow noopener" target="_blank">Dr. Farbod Farshidian</a>, <a href="https://mavt.ethz.ch/people/person-detail.hutter.html" rel="external nofollow noopener" target="_blank">Prof. Dr. Marco Hutter</a>. I worked on improving teleoperation performance using model predictive control for <a href="https://rsl.ethz.ch/robots-media/alma.html" rel="external nofollow noopener" target="_blank">ALMA</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 15, 2021</th> <td> 📝 I started to work as a student teaching assistant for <a href="https://idsc.ethz.ch/education/lectures/optimal-control.html" rel="external nofollow noopener" target="_blank">Dynamic Programming and Optimal Control</a> in HS21 from <a href="https://raffaello.name/" rel="external nofollow noopener" target="_blank">Prof. Dr. Raffaello D’Andrea</a> at ETH Zürich. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 09, 2021</th> <td> ⛰️ I spent a wonderful week at <a href="https://robotics-summerschool.ethz.ch/" rel="external nofollow noopener" target="_blank">ETH Robotics Summer School</a> in Wangen an der Aare. A broad scope of components of autonomous mobile robots including state estimation, trajectory optimization, environment mapping, and artifact detection were introduced and implemented on a wheeled platform, <a href="https://unlimited.ethz.ch/display/ROBOTX/SuperMegaBot" rel="external nofollow noopener" target="_blank">SuperMegaBot</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 14, 2020</th> <td> 🏫 I started my master program in mechanical engineering at <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zürich</a>, Switzerland. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 15, 2020</th> <td> 🎓 I received my bachelor degree in vehicle engineering from <a href="http://www.svm.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">School of Vehicle and Mobility</a>, <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>, Beijing, China. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 10, 2019</th> <td> 🎉 I was awarded Academic Excellence Scholarship again;) and Friends of Tsinghua Scholarship – German Scholarship from Tsinghua University. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 10, 2019</th> <td> 🇩🇪 I spent three wonderful weeks at <a href="https://www.academy.rwth-aachen.de/en/programs/short-courses" rel="external nofollow noopener" target="_blank">RWTH AACHEN University Winter School</a> in Aachen, Germany. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 10, 2018</th> <td> 🎉 I was awarded Academic Excellence Scholarship and Volunteer Public Service Scholarship from Tsinghua University. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 10, 2017</th> <td> 🎉 I was awarded Integrated Excellence Scholarship from Tsinghua University. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 15, 2016</th> <td> 🏫 I started my bachelor in vehicle engineering at Department of Automotive Engineering, <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>, Beijing, China. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/stmr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="stmr.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yoon2024spatio" class="col-sm-8"> <div class="title">Spatio-Temporal Motion Retargeting for Quadruped Robots</div> <div class="author"> Taerim Yoon, Dongho Kang, Seungmin Kim, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Minsung Ahn, Jin Cheng, Stelian Coros, Sungjoon Choi' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Robotics (T-RO)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2404.11557" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>This work introduces a motion retargeting approach for legged robots, which aims to create motion controllers that imitate the fine behavior of animals. Our approach, namely spatio-temporal motion retargeting (STMR), guides imitation learning procedures by transferring motion from source to target, effectively bridging the morphological disparities by ensuring the feasibility of imitation on the target system. Our STMR method comprises two components: spatial motion retargeting (SMR) and temporal motion retargeting (TMR). On the one hand, SMR tackles motion retargeting at the kinematic level by generating kinematically feasible whole-body motions from keypoint trajectories. On the other hand, TMR aims to retarget motion at the dynamic level by optimizing motion in the temporal domain. We showcase the effectiveness of our method in facilitating Imitation Learning (IL) for complex animal movements through a series of simulation and hardware experiments. In these experiments, our STMR method successfully tailored complex animal motions from various media, including video captured by a hand-held camera, to fit the morphology and physical properties of the target robots. This enabled RL policy training for precise motion tracking, while baseline methods struggled with highly dynamic motion involving flying phases. Moreover, we validated that the control policy can successfully imitate six different motions in two quadruped robots with different dimensions and physical properties in real-world settings.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/sata.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sata.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="li2025sata" class="col-sm-8"> <div class="title">SATA: Safe and Adaptive Torque-Based Locomotion Policies Inspired by Animal Learning</div> <div class="author"> Peizhuo Li, Hongyi Li, Ge Sun, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Jin Cheng, Xinrong Yang, Guillaume Bellegarda, Milad Shafiee, Yuhong Cao, Auke Ijspeert, Guillaume Sartoretti' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>2025 Robotics: Science and Systems (RSS 2025)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.12674" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>Despite recent advances in learning-based controllers for legged robots, deployments in human-centric environments remain limited by safety concerns. Most of these approaches use position-based control, where policies output target joint angles that must be processed by a low-level controller (e.g., PD or impedance controllers) to compute joint torques. Although impressive results have been achieved in controlled real-world scenarios, these methods often struggle with compliance and adaptability when encountering environments or disturbances unseen during training, potentially resulting in extreme or unsafe behaviors. Inspired by how animals achieve smooth and adaptive movements by controlling muscle extension and contraction, torque-based policies offer a promising alternative by enabling precise and direct control of the actuators in torque space. In principle, this approach facilitates more effective interactions with the environment, resulting in safer and more adaptable behaviors. However, challenges such as a highly nonlinear state space and inefficient exploration during training have hindered their broader adoption. To address these limitations, we propose SATA, a bio-inspired framework that mimics key biomechanical principles and adaptive learning mechanisms observed in animal locomotion. Our approach effectively addresses the inherent challenges of learning torque-based policies by significantly improving early-stage exploration, leading to high-performance final policies. Remarkably, our method achieves zero-shot sim-to-real transfer. Our experimental results indicate that SATA demonstrates remarkable compliance and safety, even in challenging environments such as soft/slippery terrain or narrow passages, and under significant external disturbances, highlighting its potential for practical deployments in human-centric and safety-critical scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/robotkeyframing.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="robotkeyframing.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="fzargarbashi2024robotkeyframing" class="col-sm-8"> <div class="title">RobotKeyframing: Learning Locomotion with High-Level Objectives via Mixture of Dense and Sparse Rewards</div> <div class="author"> Fatemeh Zargarbashi, Jin Cheng, Dongho Kang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Robert Sumner, Stelian Coros' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>2024 Conference on Robot Learning (CoRL 2024)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2407.11562" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://studios.disneyresearch.com/2024/11/04/robotkeyframing-learning-locomotion-with-high-level-objectives/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/YpOABpwdxko?si=zzSUEVTdQ3FATnhW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://sites.google.com/view/robot-keyframing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This paper presents a novel learning-based control framework that uses keyframing to incorporate high-level objectives in natural locomotion for legged robots. These high-level objectives are specified as a variable number of partial or complete pose targets that are spaced arbitrarily in time. Our proposed framework utilizes a multi-critic reinforcement learning algorithm to effectively handle the mixture of dense and sparse rewards. Additionally, it employs a transformer-based encoder to accommodate a variable number of input targets, each associated with specific time-to-arrivals. Throughout simulation and hardware experiments, we demonstrate that our framework can effectively satisfy the target keyframe sequence at the required times. In the experiments, the multi-critic method significantly reduces the effort of hyperparameter tuning compared to the standard single-critic alternative. Moreover, the proposed transformer-based architecture enables robots to anticipate future goals, which results in quantitative improvements in their ability to reach their targets.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/doi3.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="doi3.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vlastelica2023diverse" class="col-sm-8"> <div class="title">Offline Diversity Maximization Under Imitation Constraints</div> <div class="author"> Marin Vlastelica, Jin Cheng, Georg Martius, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Pavel Kolev' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>2024 Reinforcement Learning Conference (RLC 2024)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2307.11373" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://rlj.cs.umass.edu/2024/papers/Paper169.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://sites.google.com/view/diversity-via-duality/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>There has been significant recent progress in the area of unsupervised skill discovery, utilizing various information-theoretic objectives as measures of diversity. Despite these advances, challenges remain: current methods require significant online interaction, fail to leverage vast amounts of available task-agnostic data and typically lack a quantitative measure of skill utility. We address these challenges by proposing a principled offline algorithm for unsupervised skill discovery that, in addition to maximizing diversity, ensures that each learned skill imitates state-only expert demonstrations to a certain degree. Our main analytical contribution is to connect Fenchel duality, reinforcement learning, and unsupervised skill discovery to maximize a mutual information objective subject to KL-divergence state occupancy constraints. Furthermore, we demonstrate the effectiveness of our method on the standard offline benchmark D4RL and on a custom offline dataset collected from a 12-DoF quadruped robot for which the policies trained in simulation transfer well to the real robotic system.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/dominic.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dominic.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cheng2023learning" class="col-sm-8"> <div class="title">Learning Diverse Skills for Local Navigation under Multi-constraint Optimality</div> <div class="author"> Jin Cheng, Marin Vlastelica, Pavel Kolev, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Chenhao Li, Georg Martius' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>2024 IEEE International Conference on Robotics and Automation (ICRA 2024)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2310.02440" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/document/10611629" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtube.com/playlist?list=PLUPeAQ-E3nrVdeZ4ZZYy0kQNX3pb4szJL&amp;si=Su91ojeOn3etjcuG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://sites.google.com/view/icra2024-dominic" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Despite many successful applications of data-driven control in robotics, extracting meaningful diverse behaviors remains a challenge. Typically, task performance needs to be compromised in order to achieve diversity. In many scenarios, task requirements are specified as a multitude of reward terms, each requiring a different trade-off. In this work, we take a constrained optimization viewpoint on the quality-diversity trade-off and show that we can obtain diverse policies while imposing constraints on their value functions which are defined through distinct rewards. In line with previous work, further control of the diversity level can be achieved through an attract-repel reward term motivated by the Van der Waals force. We demonstrate the effectiveness of our method on a local navigation task where a quadruped robot needs to reach the target within a finite horizon. Finally, our trained policies transfer well to the real 12-DoF quadruped robot, Solo12, and exhibit diverse agile behaviors with successful obstacle traversal.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/rl+.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rl+.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kang2023rl+" class="col-sm-8"> <div class="title">RL+ Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion</div> <div class="author"> Dongho Kang, Jin Cheng, Miguel Zamora, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Fatemeh Zargarbashi, Stelian Coros' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.17842" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/document/10225268" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/gXDP87yVq4o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://donghok.me/rl-plus-model-based-control/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This letter presents a versatile control method for dynamic and robust legged locomotion that integrates model-based optimal control with reinforcement learning (RL). Our approach involves training an RL policy to imitate reference motions generated on-demand through solving a finite-horizon optimal control problem. This integration enables the policy to leverage human expertise in generating motions to imitate while also allowing it to generalize to more complex scenarios that require a more complex dynamics model. Our method successfully learns control policies capable of generating diverse quadrupedal gait patterns and maintaining stability against unexpected external perturbations in both simulation and hardware experiments. Furthermore, we demonstrate the adaptability of our method to more complex locomotion tasks on uneven terrain without the need for excessive reward shaping or hyperparameter tuning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/haptic_teleoperation.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="haptic_teleoperation.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cheng2022haptic" class="col-sm-8"> <div class="title">Haptic Teleoperation of High-dimensional Robotic Systems Using a Feedback MPC Framework</div> <div class="author"> Jin Cheng, Firas Abi-Farraj, Farbod Farshidian, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marco Hutter' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2207.14635" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/abstract/document/9981290" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/OiprDWv0OcE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Model Predictive Control (MPC) schemes have proven their efficiency in controlling high degree-of-freedom (DoF) complex robotic systems. However, they come at a high computational cost and an update rate of about tens of hertz. This relatively slow update rate hinders the possibility of stable haptic teleoperation of such systems since the slow feedback loops can cause instabilities and loss of transparency to the operator. This work presents a novel framework for transparent teleoperation of MPC-controlled complex robotic systems. In particular, we employ a feedback MPC approach [1] and exploit its structure to account for the operator input at a fast rate which is independent of the update rate of the MPC loop itself. We demonstrate our framework on a mobile manipulator platform and show that it significantly improves haptic teleoperation’s transparency and stability. We also highlight that the proposed feedback structure is constraint satisfactory and does not violate any constraints defined in the optimal control problem. To the best of our knowledge, this work is the first realization of the bilateral teleoperation of a legged manipulator using a whole-body MPC framework.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6A%69%6E-%63%68%65%6E%67@%69%6E%66.%65%74%68%7A.%63%68" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/catachiii" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/jin-cheng-886462163" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=jHsJrX8AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/catachiii" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://youtube.com/@jincheng5662" title="YouTube" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-youtube"></i></a> </div> <div class="contact-note">Please feel free to contact me with jin.cheng(at)inf.ethz.ch </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Jin Cheng. Last updated: July 11, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-9LNT68FN1H"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-9LNT68FN1H');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>